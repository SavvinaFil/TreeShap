# AI Explainability Toolbox

**Model-agnostic interpretability analysis for any AI tool.**

This toolbox provides a standardized framework for explaining AI model predictions using SHAP (SHapley Additive exPlanations). It is designed to be model-agnostic, supporting both traditional machine learning (Scikit-Learn) and deep learning (PyTorch/LSTM) workflows.

---

## ğŸ” Overview

This repository provides an automated pipeline to move from a trained model to a professional interpretability report. By utilizing a configuration-driven approach, users can generate audit-ready Excel files and pre-rendered Jupyter Notebooks without writing new code for every model.

---

## ğŸ“ Repository Structure

```text
/
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ tabular/                # Logic for CSV-based data (RF, XGB, etc.)
â”‚   â”‚   â”œâ”€â”€ treebased/          # Tree-specific explainers
â”‚   â”‚   â””â”€â”€ __init__.py         # Tabular manager and registry
â”‚   â””â”€â”€ timeseries/             # Logic for 3D temporal data (LSTM, GRU)
â”‚       â””â”€â”€ lstm_explainer.py   # PyTorch-specific SHAP implementation
â”‚
â”œâ”€â”€ output/                     # Generated Reports and Audit logs
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ report_gen.py       # The core Notebook generation engine
â”‚   â””â”€â”€ (files)                 # .xlsx and .ipynb outputs appear here
â”‚
â”œâ”€â”€ source/                     # Input Assets
â”‚   â”œâ”€â”€ models/                 # Your .pkl or .pt model files
â”‚   â””â”€â”€ data/                   # Your .csv or .pt data files
â”‚
â”œâ”€â”€ examples/                   # Pre-configured JSON templates
â”œâ”€â”€ main.py                     # Central entry point
â””â”€â”€ README.md
```

## ğŸš€ Getting Started

### 1. Prepare your Assets
Place your trained model and the dataset you want to explain in the `source/` directory:
* **Tabular:** `.pkl` model and `.csv` data.
* **Time-Series:** `.pt` PyTorch model and `.pt` pre-processed tensors.

### 2. Configure your Analysis
Create a JSON file to define the analysis scope. This file tells the toolbox where your files are and how to interpret the outputs.

<details>
<summary><b>Example: Tabular Multi-Target Regression (config.json)</b></summary>

```json
{
  "analysis": "tabular",
  "model_type": "random_forest",
  "model_path": "source/models/energy_model.pkl",
  "dataset_path": "source/data/energy_data.csv",
  "output_dir": "output/",
  "feature_names": ["Wind_Speed", "Temp", "Humidity"],
  "target_index": [0, 1, 2],
  "output_labels": {
    "0": "Power Generation",
    "1": "Grid Load",
    "2": "Frequency"
  },
  "save_excel": true,
  "generate_notebook": true
}
```
</details>

### 3. Run the Toolbox
Execute the analysis via the command line using the `--config` flag:

* Run Time-Series Analysis
```bash
python main.py --config examples/timeseries/lstm/config.json
```

* Run Tabular Classification
```bash
python main.py --config examples/tabular/classify/config.json
```

* Run Tabular Regression
```bash
python main.py --config examples/tabular/regress/config.json
```

---

## ğŸ“Š Outputs

The toolbox generates two primary artifacts in the output/ folder:

1. SHAP Audit (.xlsx): A multi-sheet spreadsheet containing original feature values, model predictions, and SHAP values for every row. Each target index gets its own sheet.
2. Interpretation Report (.ipynb): A fully executed Jupyter Notebook containing Summary Plots, Feature Importance Bar Charts, and Temporal Analysis (for LSTMs).

You can find examples of the jupyter notebooks here:

|   | **Single Output Regression**  | **Binary Classification** | **Multioutput Regression** |
| **Example** | [LSTM report](./output/explanation_lstm_gradient_20260220_143820.ipynb) | [RF Classify Report](./output/multi_report_random_forrest_20260220_143844.ipynb) | [RF Regress Report](./output/multi_report_random_forrest_20260220_143908.ipynb) |

---

## ğŸ› ï¸ Supported Models
* Tree-Based: RandomForest, XGBoost, DecisionTrees.
* Deep Learning: LSTM, GRU, MLP (PyTorch, some still under construction).
* Multi-Output: Full support for MultiOutputRegressor and MultiOutputClassifier wrappers.